{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vex99np2wFVt"
   },
   "source": [
    "# 03. PyTorch Computer Vision Exercises\n",
    "\n",
    "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
    "\n",
    "They're a bunch of fun.\n",
    "\n",
    "You're going to get to write plenty of code!\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
    "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
    "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
    "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaeYzOTLwWh2",
    "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
   },
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu130\n"
     ]
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# TODO: Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSFX7tc1w-en"
   },
   "source": [
    "## 1. What are 3 areas in industry where computer vision is currently being used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyWRkvWGbCXj"
   },
   "source": [
    "1. Autonomous driving\n",
    "2. Classification of different items (e.g. food detection in Calorie tracking apps)\n",
    "3. Facial recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBK-WI6YxDYa"
   },
   "source": [
    "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1rxD6GObCqh"
   },
   "source": [
    "When model is too well trained on the training set, such that it performs worse on test or actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeYFEqw8xK26"
   },
   "source": [
    "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
    "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocvOdWKcbEKr"
   },
   "source": [
    "1. Use a larger training dataset\n",
    "2. Early stopping -> stop when model performance on validation set starts to degrade\n",
    "3. Regularization -> penalty term is added to the function the model is trying to optimize. This helps prevent the model from fitting too closely to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKdEEFEqxM-8"
   },
   "source": [
    "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqZaJIRMbFtS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvf-3pODxXYI"
   },
   "source": [
    "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SHjeuN81bHza"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = MNIST(root=\"data\", train=True, transform=ToTensor(), target_transform=None, download=True)\n",
    "test_data = MNIST(root=\"data\", train=False, transform=ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxZW-uAbxe_F"
   },
   "source": [
    "## 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QVFsYi1PbItE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=6):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(len(test_samples)):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.imshow(test_samples[i].squeeze(), cmap='gray')\n",
    "    plt.title(test_data.classes[test_labels[i]])\n",
    "    plt.grid(False)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPDzW0wxhi3"
   },
   "source": [
    "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ALA6MPcFbJXQ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = train_data[0]\n",
    "\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCCVfXk5xjYS"
   },
   "source": [
    "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5IKNF22XbKYS"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, output_shape: int, hidden_units: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        X = self.conv_1(X)\n",
    "        X = self.conv_2(X)\n",
    "        X = self.classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = MNISTModel(input_shape=1, output_shape=len(test_data.classes), hidden_units=32)\n",
    "model_1 = MNISTModel(input_shape=1, output_shape=len(test_data.classes), hidden_units=32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf_3zUr7xlhy"
   },
   "source": [
    "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_0 = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
    "optimizer_1 = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
    "acc_fn = Accuracy(task='multiclass', num_classes=len(train_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               acc_fn: Accuracy,\n",
    "               device: torch.device = device):\n",
    "    '''Performs training with model trying to learn on data_loader'''\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    acc_fn = acc_fn.to(device)\n",
    "\n",
    "    # Add a loop to loop through the training batch\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate training loss\n",
    "\n",
    "        train_acc += acc_fn(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Divide total training loss and accuracy by length of train dataloader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               acc_fn: Accuracy,\n",
    "               device: torch.device = device):\n",
    "    '''Performs testing with model going over data_loader'''\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    acc_fn = acc_fn.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # Loss\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "            # Accuracy\n",
    "            test_acc += acc_fn(test_pred.argmax(dim=1), y)\n",
    "\n",
    "        # Calculate avg. test loss per batch\n",
    "        test_loss /= len(data_loader)\n",
    "\n",
    "        # Calculate test accuracy avg. per batch\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.5f}, Test acc: {test_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19428 | Train acc: 0.93703\n",
      "Test loss: 0.04590, Test acc: 0.98472\n",
      "Train loss: 0.05290 | Train acc: 0.98373\n",
      "Test loss: 0.03545, Test acc: 0.98742\n",
      "Train loss: 0.03873 | Train acc: 0.98788\n",
      "Test loss: 0.03722, Test acc: 0.98852\n",
      "Train loss: 0.03218 | Train acc: 0.98967\n",
      "Test loss: 0.03426, Test acc: 0.98752\n",
      "Train loss: 0.02597 | Train acc: 0.99195\n",
      "Test loss: 0.03146, Test acc: 0.98902\n",
      "Time taken on GPU: 50.458\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# first on GPU\n",
    "\n",
    "start_gpu = timer()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_step(model_1, train_dataloader, loss_fn, optimizer_1, acc_fn, device)\n",
    "    test_step(model_1, test_dataloader, loss_fn, acc_fn, device)\n",
    "\n",
    "end_gpu = timer()\n",
    "\n",
    "print(f\"Time taken on GPU: {(end_gpu-start_gpu):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "jSo6vVWFbNLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15628 | Train acc: 0.95402\n",
      "Test loss: 0.05958, Test acc: 0.98162\n",
      "Train loss: 0.05172 | Train acc: 0.98420\n",
      "Test loss: 0.05266, Test acc: 0.98292\n",
      "Train loss: 0.03906 | Train acc: 0.98813\n",
      "Test loss: 0.02896, Test acc: 0.99083\n",
      "Train loss: 0.03134 | Train acc: 0.99052\n",
      "Test loss: 0.02251, Test acc: 0.99302\n",
      "Train loss: 0.02724 | Train acc: 0.99140\n",
      "Test loss: 0.01865, Test acc: 0.99452\n",
      "Time taken on CPU: 104.429\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "# then on CPU\n",
    "\n",
    "start_cpu = timer()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_step(model_0, train_dataloader, loss_fn, optimizer_0, acc_fn, \"cpu\")\n",
    "    test_step(model_0, train_dataloader, loss_fn, acc_fn, \"cpu\")\n",
    "\n",
    "end_cpu = timer()\n",
    "\n",
    "print(f\"Time taken on CPU: {(end_cpu-start_cpu):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1CsHhPpxp1w"
   },
   "source": [
    "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "_YGgZvSobNxu"
   },
   "outputs": [],
   "source": [
    "def eval_model(model: nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: nn.Module, acc_fn: Accuracy, device: torch.device = device):\n",
    "    loss, acc = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    acc_fn = acc_fn.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_pred = model(X)\n",
    "\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += acc_fn(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        # Scale the loss and acc to find the average per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # works only if model was created from a class\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'MNISTModel',\n",
       " 'model_loss': 0.027102665975689888,\n",
       " 'model_acc': 0.9903154969215393}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results = eval_model(model=model_0, data_loader=test_dataloader, loss_fn=loss_fn, acc_fn=acc_fn, device=\"cpu\")\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'MNISTModel',\n",
       " 'model_loss': 0.03145873174071312,\n",
       " 'model_acc': 0.9890175461769104}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, acc_fn=acc_fn, device=device)\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQwzqlBWxrpG"
   },
   "source": [
    "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSrXiT_AbQ6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj6bDhoWxt2y"
   },
   "source": [
    "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leCTsqtSbR5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHS20cNTxwSi"
   },
   "source": [
    "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
    "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
    "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
    "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78a8LjtdbSZj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "03_pytorch_computer_vision_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
